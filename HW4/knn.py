# -*- coding: utf-8 -*-
"""knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T0LRZ4uGYJItT2yGPVUSkJq4-kmFyEeg

Import the libraries math (for square root and absolute value) and pandas and numpy for reading csv files.
"""

import math
import pandas as pd
import numpy as np

"""Make an untagged vector, point, and two tagged vectors, data1 and data2:"""

point = [1, 0, 0, 'M'] #(an unknown tag)
point2 = [6, 7, 0, 'F']


data1 = [1, 0, 0, 'M']
data2 = [1, 7, 0, 'F']
data3 = [1, 1, 1, 'M']
data4 = [6, 6, 7, 'F']
data5 = [1, 8, 0, 'M']
data6 = [6, 8, 0, 'F']
# data7 = [3, 0, 0, 'M']
# data8 = [6, 3, 0, 'F']
# data9 = [1, 0, 0, 'M']
# data10 = [1, 3, 0, 'F']
a2D = np.array([data1,data2,data3,data4,data5,data6])
a1d = np.array([point,point2])


"""Write code to separate the data (X) from the tag (Y).  Your output should be:

The vector [1, 1, 1] has tag M

The vector [1, 3, 0] has tag F

"""

print("The vector " , data1[0:-1], " has tag ", data1[-1])

"""Now let's classify the point as either M or F.  We'll do this by setting k = 1 and using the Euclidean distance.  We'll define that as: """

def euclideanDistance(instance1, instance2, length):
   distance = 0
   for x in range(length):
         #print ('x is ' , x)
         num1=float(instance1[x])
         num2=float(instance2[x])
         distance = distance + pow(num1-num2, 2)
   return math.sqrt(distance)


def manhattan(instance1, instance2,length):
    distance = 0
    for x in range(length):
            #print ('x is ' , x)
            num1=float(instance1[x])
            num2=float(instance2[x])
            distance = distance + abs(num1-num2)
    return distance

def hamming(instance1, instance2, length):
   distance = 0
   for x in range(length):
         #print ('x is ' , x)
         num1=float(instance1[x])
         num2=float(instance2[x])
         if num1 == num2:
            distance +=1
   return distance

"""Now, find out the distance between data1 and point and data2 and point. Output what the tag should be using euclideanDistance."""

# print(euclideanDistance(a2D,point,3))

"""Now, let's get more data from a file, myFile.csv. This code will read it for us:"""

url = 'https://github.com/rosenfa/ai/blob/master/myFile.csv?raw=true'
df=pd.read_csv(url,  header=0, error_bad_lines=False) 
#put data in dataset without header line
dataset = np.array(df)
print(dataset)

"""Show that you understand what you read by:

1. Printing the first two vectors in the file
2. Printing the Euclidean distance between those two vectors

Here is some code which I think might help get you on your way!
"""

print(len(dataset))
print(euclideanDistance(dataset[0],dataset[1],3))

"""Now assume you have a new value for point:

[0,0,100]

How would you classify this vector using the Euclidean distance function given all of the vectors in the file?

In order to help here is a hint:  

We suggest defining some type of data struction to store different vectors' distances and their tags like this:
"""

class distClass:
    dist = -1 #distance of current point from test point
    tag = '-' #tag of current point


"""You can then add vector distances like this:"""



def getBestEDistances(train_data,test_data,k):
    #go through each item in the test_data
    for x in test_data:
        men = 0
        women = 0
        z  = 0
        eucDistances = [] # list of distances, will hold objects of type distClass

        #compare it to each point in the train_data
        for y in train_data:
            d=euclideanDistance(x,y,x.size-1)
            obj = distClass() #one record's distance and tag
            obj.dist=d
            obj.tag = y[-1]
            eucDistances.append(obj)
        #sort the points that our point is most similar to
        eucDistances.sort(key=lambda x: x.dist)
        #see how many of these points are men vs woman
        while z < k:
            if eucDistances[z].tag == 'F':
                women += 1
            else:
                men +=1
            z+=1
        #change the test_data to what we think it is
        if men > women:
            x[-1] = 'M'
        else:
            x[-1] = 'F'
        #return the new test data
    return test_data


#repeat this process for different distances. ע"ש the notes from getBestEDistances
def getBestMDistances(train_data,test_data,k):
    
    for x in test_data:
        men = 0
        women = 0
        z  = 0
        eucDistances = [] # list of distances, will hold objects of type distClass
        for y in train_data:
            d=manhattan(x,y,x.size-1)
            obj = distClass() #one record's distance and tag
            obj.dist=d
            obj.tag = y[-1]
            eucDistances.append(obj)
        eucDistances.sort(key=lambda x: x.dist)
        while z < k:
            if eucDistances[z].tag == 'F':
                women += 1
            else:
                men +=1
            z+=1
        if men > women:
            x[-1] = 'M'
        else:
            x[-1] = 'F'
    return test_data

#repeat this process for different distances. ע"ש the notes from getBestEDistances
def getBestHDistances(train_data,test_data,k):
    for x in test_data:
        men = 0
        women = 0
        z  = 0
        eucDistances = [] # list of distances, will hold objects of type distClass
        for y in train_data:
            d=hamming(x,y,x.size-1)
            obj = distClass() #one record's distance and tag
            obj.dist=d
            obj.tag = y[-1]
            eucDistances.append(obj)
        eucDistances.sort(key=lambda x: x.dist, reverse= True)
        while z < k:
            if eucDistances[z].tag == 'F':
                women += 1
            else:
                men +=1
            z+=1
        if men > women:
            x[-1] = 'M'
        else:
            x[-1] = 'F'
    return test_data
        
        # print("jkasndfjkas" + str(men))
    # eucDistances[0].dist
            
            
    # temp=dataset[1]
    # label=temp[-1]
    
    # print("The distances between " , point , " and " , temp,  " is " , str(d))
    # print(" and the label is " + label)
    

    """and sort them like this:"""

    # eucDistances.sort(key=lambda x: x.dist)

"""Questions:

1. What is the label for point if k=1?
2. What is the label for point if k=3?
3. Would the result be different if we used a different distance function like Hamming or Manhattan?
"""

#Add code with functions that implement Hamming and Manhattan distances and test 
#what the label will be for k=1 and k=3 for all possibilities 
#(6 total: 2 Euclidean, 2 Hamming and 2 Manhattan)

"""Up until here is a simplified version of the homework.
Below here is the work for the part we will be checking as the basis of your grade:

Now let's look at some bigger files: 

1. mytrain.csv (for training the model)
2. mytest.csv (for testing)
"""
# b = a1d.copy()

# eff = getBestHDistances(a2D,a1d,3)

#gets the total number of correct answers
def getPercentageOfCorrect(answer,train_data):
    total = 0
    test = len(answer)
    for i in range(len(answer)):
            first = answer[i][-1]
            second = train_data[i][-1]
            if answer[i][-1] == train_data[i][-1]:
                total+=1
    return total

# answer = getPercentageOfCorrect(eff,b)

# print(answer)
# print("hello")
    



"""I hope by now you understand where we are going with this :)

Now implement the knn code with 3 different values for k:
1. k = 1
2. k = 7
3. k = 15

and at first use the Euclidean distance.
Classify each of the vectors in the test_data dataset using the training data from train_data.  Which value for k did the best?  What accuracy did it give you?

Now see if using Hamming or Manhattan distance give any better results for the same values of k.  

Once you are done, you should have a total of 9 different results:

1. Three results for the different value of k using the Euclidean Distance
2. Three results for the different value of k using the Hamming Distance
3. Three results for the different value of k using the Manhattan Distance

Hint: I strongly suggest you base yourself on the code you've seen until this point so you don't have to reinvent the wheel!
"""

#Add code here
url = 'https://github.com/rosenfa/ai/blob/master/mytrain.csv?raw=true'
train_data = np.array(pd.read_csv(url,  header=0, error_bad_lines=False))
url = 'https://github.com/rosenfa/ai/blob/master/mytest.csv?raw=true'
test_data = np.array(pd.read_csv(url,  header=0, error_bad_lines=False))

print(train_data.shape)# number of records and features
print(train_data)

print(test_data.shape)# number of records and features
print(test_data)

#Euclidean distance tests:
#returns what we assume each gender is in the test_data
answer  = getBestEDistances(train_data,test_data,15)
train_data = np.array(pd.read_csv(url,  header=0, error_bad_lines=False))
#compares what we got to what it actual was
#returns the correct numbers
number = getPercentageOfCorrect(answer,train_data)
print(number)

#repeat the process for other distances

#Manhattan distance tests
# answer = getBestMDistances(train_data,test_data,15) #works
# train_data = np.array(pd.read_csv(url,  header=0, error_bad_lines=False))
# number = getPercentageOfCorrect(answer,train_data)
# print(number)


#hamming distance tests
# answer = getBestHDistances(train_data,test_data,15)
# train_data = np.array(pd.read_csv(url,  header=0, error_bad_lines=False))
# number = getPercentageOfCorrect(answer,train_data)
# print(number)


"""
Euclidean:
When k = 1, 50 were correct

When k = 7, 74 were correct

When k = 15, 70 were correct


Manhattan:
When k = 1, 61 were correct

When k = 7, 63 were correct

When k = 15, 69 were correct



Hamming:
When k = 1, 61 were correct

When k = 7, 55 were correct

When k = 15, 57 were correct

"""

"""Grade Basis:

80% for correct answers (and yes, there are possibilities that multiple answers are correct-- especially for cases of ties).

20% : Documentation and easily readable code

Please publish your final Notebook in your Github directory.

The homework assignment is due by November 30th.

"""

